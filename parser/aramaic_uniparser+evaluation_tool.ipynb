{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# UniParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: uniparser_morph in /home/sofia1236/.local/lib/python3.8/site-packages (2.7.5)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install uniparser_morph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from uniparser_morph import Analyzer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialise analyzer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = Analyzer()\n",
    "a.load_grammar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pass a word:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<Wordform object>\n",
      "ġamlax\n",
      "ġamla; NOUN,POSS.2ms,Sg,m\n",
      "ġaml-ax\n",
      "STEM=2ms\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "analyses=a.analyze_words(\"ġamlax\")\n",
    "print(analyses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wordform:  ġamlax\n",
      "lemma:  ġamla\n",
      "grammatical features:  NOUN,m,Sg,POSS.2ms\n",
      "glossed wordform:  ġaml-ax\n",
      "glosses:  STEM=2ms\n"
     ]
    }
   ],
   "source": [
    "for ana in analyses:\n",
    "      print(\"wordform: \", ana.wf)\n",
    "      print(\"lemma: \", ana.lemma)\n",
    "      print(\"grammatical features: \", ana.gramm)\n",
    "      print(\"glossed wordform: \", ana.wfGlossed)\n",
    "      print(\"glosses: \", ana.gloss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or a list of words:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\tana\tana\tPRON\tpron_type=Pers|person=1|number=Sg\tana\tI\n",
      "2\txett\txett\tADV\tadv_type=Mod\txett\tSTEM\n",
      "3\tbatt\tabət yabət|batte\tAUX|VERB\tStamm=IVy|tense=Perf|person=3|number=Sg|gender=m | person=1|number=Sg|gender=c\tbatt\tFUT|STEM\n",
      "4\tṯinaġelča\tṯinaġelča\tNOUN\tgender=f|number=Sg\tṯinaġel-č-a\tSTEM-F-FREE\n",
      "\n"
     ]
    }
   ],
   "source": [
    "analyses = a.analyze_words(['ana', 'xett', 'batt', 'ṯinaġelča'], format=\"conll\")\n",
    "print(analyses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If do not have prepared list of words, you can use this function to get it from text strings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_to_tok(text_to_gloss):\n",
    "    first_tokens = nltk.word_tokenize(text_to_gloss)\n",
    "    final_tokens=[]\n",
    "    for tok in first_tokens:\n",
    "        tok=tok.lower()\n",
    "        if \"-\" in tok:\n",
    "            final_tokens.extend(tok.split(\"-\"))\n",
    "        elif \"_\" in tok:\n",
    "            final_tokens.extend(tok.split(\"_\"))\n",
    "        elif tok.isalpha() or \"ḏ̣\" in tok:\n",
    "            final_tokens.append(tok)\n",
    "    return final_tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation tool"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To evaluate morphological parser two functions below can be used: the first one (`get_gold_annotation`) prepares gold annotation in certain format and the second one (`get_annotation_scores`) prints number of all words, number of totally correct words (i. e. words which have correct lemma, pos-tag and grammtical features simultaneously), weighted arithmetic mean and returns a dataframe with correct number of lemmata, pos-tags and grammatical features per part of speech (both number and percentage)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare gold annotation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotations=[]\n",
    "g=open(\"annotation.txt\", \"r\", encoding=\"utf-8\")\n",
    "ann_sentence=[]\n",
    "for line in g:\n",
    "    if line.startswith(\"0\") or line.startswith(\"3\"):\n",
    "        if len(ann_sentence)>0:\n",
    "            annotations.append(ann_sentence)\n",
    "        ann_sentence=[]\n",
    "    if \"\\t\\t\" in line:\n",
    "        help_ann=[]\n",
    "        line_splitted=line.split(\"\\t\\t\")[:3]\n",
    "        if line_splitted[1]!=\"EMPTY\":\n",
    "            help_ann.append(line_splitted[0][:-1])\n",
    "            help_ann.append(line_splitted[1])\n",
    "            grams=line_splitted[-1].split(\",\")\n",
    "            help_ann.append(grams[0])\n",
    "            help_ann.append(set(grams[1:]))\n",
    "            ann_sentence.append(help_ann)\n",
    "        \n",
    "g.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is how it looks like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['ē', 'ē', 'PART', set()], ['čbōʕin', 'ibəʕ yibəʕ', 'VERB', {'Prs', '2', 'Pl', 'm', 'I'}], ['nišw', 'išw yišw', 'VERB', {'Subj', 'Pl', 'c', '1', 'I'}], ['ḥenna', 'ḥenna', 'NOUN', {'m', 'Sg'}]]\n"
     ]
    }
   ],
   "source": [
    "print(annotations[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gold_annotation(gold_annotation):\n",
    "    \n",
    "    g=open(gold_annotation, \"r\", encoding=\"utf-8\")\n",
    "    \n",
    "    annotations_non_empty=[]\n",
    "    annotations_all=[]\n",
    "    annotations_non_empty_unique=[]\n",
    "    annotations_all_unique=[]\n",
    "    \n",
    "    for line in g:        \n",
    "        \n",
    "        if \"\\t\\t\" in line:\n",
    "            help_ann=[]\n",
    "            line_splitted=line.split(\"\\t\\t\")[:3]\n",
    "            help_ann.append(line_splitted[0][:-1])\n",
    "            help_ann.append(line_splitted[1])\n",
    "            grams=line_splitted[-1].split(\",\")\n",
    "            help_ann.append(grams[0])\n",
    "            help_ann.append(set(grams[1:]))\n",
    "            annotations_all.append(help_ann)\n",
    "            if help_ann not in annotations_all_unique:\n",
    "                annotations_all_unique.append(help_ann)\n",
    "            \n",
    "            help_ann2=[]\n",
    "            if line_splitted[1]!=\"EMPTY\":\n",
    "                help_ann2.append(line_splitted[0][:-1])\n",
    "                help_ann2.append(line_splitted[1])\n",
    "                grams=line_splitted[-1].split(\",\")\n",
    "                help_ann2.append(grams[0])\n",
    "                help_ann2.append(set(grams[1:]))\n",
    "                annotations_non_empty.append(help_ann2)\n",
    "                if help_ann2 not in annotations_non_empty_unique:\n",
    "                    annotations_non_empty_unique.append(help_ann2) \n",
    "    g.close()\n",
    "    \n",
    "    return annotations_all, annotations_all_unique, annotations_non_empty, annotations_non_empty_unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "ann1,ann2,ann3,ann4=get_gold_annotation(\"annotation.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "List of sents on which check is done:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    }
   ],
   "source": [
    "sents_ann=['005. «ē, čbōʕin nišw ḥenna?»', '014. bōṯar irpiʕ yūm mʕawītin xett mayṯyin ḏbīḥča, naxsilla.', '0. ḳarribōye ḳaʕyin b-anna payṯa, mayṯyin ḳurʔān w ḳaryill lanna ḳurʔān mn-awwalče l-axerče.', '016. ḳōymin ommṯa bakkar, nōḥčin ʕa žēmʕa ʕam-ṣallyin w zlillun ʕa žappōnča.', '003. zlallen ʕṣofra yzūran.', '004. hū čū ōxel menna, mōrəl ḏ̣ḥīṯa ču maḥiḳḳle yīxul, yḏuḳenne bnaw bnawb, yīxul menna.', '009. amrulla: «nḥūč!» niḥčaṯ, niḥčaṯ ʕal-ōḏ mʕarrṯa.', '004. ḳaʕya willa la iḥmaṯ illa iʕber aʕla, iʕber aʕla, iḏʕaṯ hī.', '015. ʕala ṭūl mičwaḥḥ bē w ʕala ṭūl p-ḥaṣṣir rayše w iṭleb menne metti w batte yapplēle.', '003. ōṯ ġabrōna, wōb b-ġayrib blōta w ōṯ.', '001. b-zamōne ṯōle aḥḥaḏ dumōnay l-ōxa, ōmar mbaḳḳar p-šaġəlṯil mōya p-ḳīsa.', '016. ē, lōmar, la karr, aḳam ōčem ikbet b-ḏokkṯe w iḳəʕ, w hōṯa mafizza.', '004. b-zamōna ʕaččīḳa msawəlfin wōṯ ḏēba rōfeḳ ṯaʕla malʕun w inžes w šūne lēle rfīḳa ġassem maʕ ḏibō ti iṯḳen mamrille yičwaʕʕ menne w yabʕeḏ meʕle.', '028. mʕapparlun ṯaʕla ʕa mahle w ōxel, w minəpṣaṭ hū w bnōye w eččṯe.', '007. b-anna tarba allxinnaḥ, // w meʕle lorkaʕ ʕawitinnaḥ. // p-ḥaṣṣiš šenna šaʕʕlinnaḥ, // w ʕa šenna irčfaʕ ṣlība.', '003. b-ʕaynōš nḥamēl kawna. // ʕaya la amrīšəl b-riḥmūṯiš? // ʕaya ḏikkliš aʕəl, amrīšəl: čimʕawīta. // hašš warṯṯa, ʕaya la affīšən nzurʕenna b-lipp?', '004. inəbraḏ — ext bann nišwi? // bann nišči ḳūrəl mišwi, // w mina mann nayṯi ḥamra?', '001. ḥmičča sallīḳa ʕa ḏayra // w zannīra b-zunnōrəs sayra // w lippi la irḥam ġayra // w hōḏ raḥme, berčis sōba.', '004. amrōli: «payṯaḥ iʕli». // amrilla: «p-ḥaṣṣe nṭayyer.»', '002. hōš nizlōli ʕa payṯa w niṯyōli, // immi p-tarba hōši minčaḳyōli. // hačči l-ḥōlax zellax w_ana l-ḥōli, // w ʕrōba čḳōmez ʕa payṯa ḳmōza.', '004. awʕax čīmar: batt w batt // mn-ōt tunya, tunya mīṯa. // barnōša ʕa ḥōle mʕatt // mn-īḏe isḳaṭ bə-ḥṭīṯa.', '012. yīfuš ti čṯēx l-ġappe, // čmiščaḥ ġawza w pšōṯa, // ōxel w mišwi b-ʕoppe, // w šōḳel m-maḥərmōṯa.', '011. xēfəl matōra ḳōtrin ʕa baġla w mafčel ḥetta yṯuḳnun ex ḥmīra.', '006. maḳimill lanna nšīfa w mawḳfin maʕ ġrōsa, ṯyillun atar ġayrayy, xett šappō, ḳaʕyillun ʕal-ōġ ġrōrča, ġōrsin w mʕannyin w masəkrin w mbaṣṭin.', '018. čūb ext_imōḏ, imōḏ ḥarīma baḥar čannīḥan, awwalča ḥarīma baḥar čaʕbōnan.', '009. nafḏiṯ l-ellel, niḥčiṯ ʕa mʕarrṯa, lā ōṯ ʕimm nohra w lā ōṯ ʕimm mett.', '015. ḳōmiṯ zlill ʕa napka.', '009. w ḥrēna žabḏunne mōya ḥetta amṭunne r-reḥyil ḳamṣa l-awwalčiš šiḳya.', '010. ḏukkil ataḳ mōyər rayša, amrilla: «wuš ḳʕāš niḥəm!»', '005. mišwille b-ann finžanō, mišwille ʕa ffōye ġawzō másalan mšakklille, w mḏ̣ayīfin bē.', '028. «nōz nišč nofəšṯa.»', '016. nmišwille ʕal-anna ġāz, w nmayṯyin kuppōyṯa w nmayṯyin maṣṣōṣča w nmayṯyin ʕolpṯis sukker w nmišwillen ḳummaynaḥ.', '005. xaṭərṯa aʕzmannaḥ ḥōl nislaḳ leʕle ʕa mazraʕṯa nsaʕitenne p-ḳulḳās w filō.', '001. xarma raḏyille xanūnay w raḏyille ʕamlay.', '009. w ōbəl xalil ʕam-nayyarəl ʕaraḳ w əl-māza, w ayṯull lanna mšammaʕ w fartunne ʕa mluṯṯil lōḏ sahəlṯa.', '005. nmišwēle p-ḳoffṯa w nkamarle ḥamša šečča yūm.', '018. amrille: «lā, bann nzill.»', '003. awwalča miččažʕin ommṯa hōxa bə-blōta — čūṯ ḥkimō.', '016. ṯill ayṯiččil lōx xšurīṯa w zabničča, w ayṯiṯ maḳəḏḥa, w ṯiḳniṯ nmišwēla ḳiḏḥō ḳiḏḥō l-ōx xšurīṯa.', '006. baʕdēn nḳatrilla m-ṭarfa p-ḥūṭa.', '090. ʕayniṯ ana, aʕžbačč ʕezza, nḳōyem mamelle: «hōʕ ʕezza p-ṯmēn warḳan. ayṯa kmōlča!»', '010. ōmar: «wrāx, la yʕaṣṣrunnaḥ!»', '008. amrille: «wrāx, ana ču nfakker nḳaṭʕiṯ ʕa tarba ġēr l-emmat šarikiččax.»', '039. bess yḥassel ramla xulle sawa, yīb iṯḳen felkiš šaʕṯa, yaʕni ʕisər w ḥammeš miṣrōyan.', '004. w ġufərlēḥ ḥṭiyōṯaḥ, // ex min nġafərlill ti maḥṭ ʕimmaynaḥ.', '003. mayṯyin ḥiṭṭō w xušnō w sʕarō w zarʕillun p-ṣaḥnō zʕūrin xann, ḥetta yirbun.', '014. rēbeʕ ḥašoppa m-ṣawma ušme ḥašoppa ti zahra w warta.', '009. bess yḥassel xenša w čḥassel ṣlōṯa, xett mražīʕin tōpkin ext_awwal yōma lə-ʕrōba.', '008. m-mar lawandīyus ṣlōṯa l-ʕāde.', '003. hanna yōma, yōmlə sčašhet bē hanna ḳattēša šwunne ʕēḏa lēle.', '045. ṯōḳen tōḳeḳ naḳōsəl mar_ilyas w naḳōsəl berkṯa w ġayre w sawōye l-ḥāṣlo.', '007. hann mašəʕlō ṯōḳnin ḳīsa, ṭūle mett iṯər mičər, šammen xann ḳalles, w b-rayšil ḳīsa ōṯ ʕolpṯa m-ḥatīta aw ṣōža.', '035. w hōxa atar mballeš... šaġlōṯa ḥrinyōṯa.', '004. mḥáttitin yōma ti batte yišwull awwal ʔurbāne bē.', '033. čbaḳḳaṯ xann ṭūlčil ḥayōṯa.', '005. ōmar: «ē!»', '013. «ču nimkarr, imeṯ ḏōḏ.»', '011. amerlun: «ḥmōn hōxa ġapplə šbabō!»', '004. ōmar: «ʕṣofra.»', '010. «hačč mō čayyeṯ?»', '012. aḳam alṭun rayḥan batte yṣōraʕ hū w ayyub.', '003. anaḥ šimʕinnaḥ keləmṯa, affiččun ču tayyirill balayy w ḳōmiṯ zlill ščiččil ḥamra.', '001. xaṭərṯa nībin nsallīḳin m-dūma, nassīḳin banadōra mxaramča l-šarāb.', '002. bess ḥmiččun ana — sakrōnin —, ḳōmiṯ sakkriṯ w šamṭiṯ minnayy.', '011. w haṯinn aʕleḳ b baʕḏ̣inn w anaḥ hōxa nḏ̣ōḥkin.', '040. batte yizʕuḳ «yā ʕaḏra», lorkaʕ infeḳ ḥesse.', '001. wōṯ l-aḥḥaḏ ġabrōna eččṯa, čuṯ šunīṯa aḥla menna b-ʕōlma.', '004. yōma mn-ann yumō infeḳ ōbəl yawse ʕa ʕarḳūba ti baʕʕeḏ ḥetta yayṯ ḳalles ḏlūḳa, ḳalles xšūra, willa išmeʕ ḥessa.', '354. «ana mann napplēle!»', '091. amrōle: «ana ḳiṣəṯ xāāānn xāāānn xāāānn. affḳanni bnōṯəl ḥōlčax, aḳʕanni p-šimša.', '035. amrilla: la, atʕāy aʕle!', '003. amella: «mō bann niščġel?»', '012. wōb ʕam-fakkar yḳuṭlenne, bess la irəṣ.', '021. amrōla: «uxxul ma čmaḥəḳya čaffeḳ m-ṯimmiš žawəhrōṯa!»', '007. sčahtaṯ ʕal_eḥḏa, ḳōyma hōḏ amralla: «ṭalpiš ġapp ana. šarṭōš hann arpʕa ana nwaffīḳa ʕlayy w nraṣṣīya bōn.»', '012. išw semla w iḳlab, willa ḳaʕya elġul mapṣūṭ, amella: «wrēš mō ḳiṣṣṯiš?»', '025. aḳam applēle.', '017. aḳam ʕṣofra ščḥunne arḥel.', '015. taššrunne w zalle.', '012. isleḳ lahhīyin ʕam-mōxlin.', '004. bōṯar čiḳrīban felkiš šaʕṯa aḳa ḥōne ščafəḳte.', '010. bess hū m-zaʕle w ʕemmiš šaṯṯ w hōṯe ičbar p-xōṭre, miḥəl ḏrōʕe mett yaffeḳ besra, aḳam ameṯ.', '014. amrulle: «čūṯ ġappaynaḥ.»', '023. ʕōbra, w surtōbiš šenna rabbi.', '033. ḏukkil iṭlab xōla, aḳam hann ḥkimō čʕažžab lə-brōm wakīn.', '021. amelle: «fōk hann ḥablō m-ʕal-anna ġešra!»', '007. ḳʕōle mišṭaʕ b-iṯər sayf, ṭarḳil īḏe p-ḥelsil awwal aḥḥaḏ w ōfez, ḳaṭṭaʕ maʕ šobʕa ḥōḏ, maʕ šobʕa ḥmōr.', '003. zōyʕin menne ommṯa, hū ižreʕ, ču mahemmle.', '003. aḳa hanna šappa batte yṣaḥḥenna, amella: «ḳūm yḳuṭʕell ʕumriš! ana ʕanmōzaḥ ʕimmiš.»', '005. baʕdēn illa naffeḏ aḥḥaḏ mažnun xwōṯe amellun: «ana nmaḥḥečle.»', '001. ōṯ ġabrōna m-ḥilpul, ġappe psōna ʕomre uppe eʕsar išən.', '004. xaṭpa w kallel aʕla.', '003. waḳčil ḥimne ḥkīma xann, amelle: «xalaṣ, hačči ṯiḳnič kayyes, šoppṯa ḥrīṯa bann naffennax čzellax ʕa tiḏōx, lōfaš uppax mett.»', '012. amelle: «ʕalle mʕallaḳ ʕa ṯarʕit tikkōna!»', '011. waxma taḳḳe w naʕʕme w šūne ʕa ffōyəl ʕolpṯa w zalle l-ʕa harūn ər-rašīd.', '004. amrōle: «ē, ṭabʕan, nyaḏḏīʕa innu ṯiḳninnaḥ šaxṣa aḥḥaḏ, bess la činəš čiṭlub xōla l-iṯər!»', '010. aḥref ebre zʕōra, amelle: «ana nhamešle w nmaṣeṣle w ntaḳeḳle w nsafefle.»', '011. amelle: «ana nʔažərlēle ḥmōra nʔažərlēle fayya?»', '003. maʕzmōle: «čfaḏ̣ḏ̣āl yā ḳašīša, našḳennax ḳahwe, čfaḏ̣ḏ̣āl!»', '005. W-ḥayyil l-ann ʕaynō! Čūl meʕle ġnō. // Ex ūle leppa yiṣlinni ex ṣafərnō.']\n",
    "print(len(sents_ann))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get four different annotation scores:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_annotation_scores(annotations, sents_ann):\n",
    "    \n",
    "    all=0\n",
    "    correct=0\n",
    "\n",
    "    scores={}\n",
    "    posses=[\"NOUN\", \"VERB\", \"AUX\", \"ADJ\", \"ADV\", \"PRON\", \"NUM\", \"SCONJ\", \"CCONJ\", \"DET\", \"PREP\", \"PART\", \"INTJ\", \"PROPN\", \"all\"]\n",
    "    for elem in posses:\n",
    "        scores[elem]={\"total\": 0, \"total_percent\": 0, \"corr_lemma\": 0, \"corr_lemma_percent\": 0, \"corr_pos\": 0, \"corr_pos_percent\": 0, \"corr_gramm\": 0, \"corr_gramm_percent\": 0}\n",
    "\n",
    "\n",
    "    all=len(annotations)\n",
    "    for an_word in annotations:\n",
    "            \n",
    "        analyses = a.analyze_words(an_word[0])\n",
    "        pos_tag=an_word[2]\n",
    "        scores[pos_tag][\"total\"]+=1\n",
    "\n",
    "        p=True\n",
    "        q=True\n",
    "        r=True\n",
    "\n",
    "        for ana in analyses:\n",
    "            if ana.lemma!=\"\":\n",
    "                    \n",
    "                if p==True:\n",
    "                    if ana.lemma==an_word[1]:\n",
    "                        scores[pos_tag][\"corr_lemma\"]+=1\n",
    "                        p=False\n",
    "                if q==True:\n",
    "                    if ana.gramm.split(\",\")[0]==pos_tag:\n",
    "                        scores[pos_tag][\"corr_pos\"]+=1\n",
    "                        q=False\n",
    "                if r==True:\n",
    "                    if set(ana.gramm.split(\",\")[1:])==an_word[3]:\n",
    "                        scores[pos_tag][\"corr_gramm\"]+=1\n",
    "                        r=False\n",
    "                \n",
    "                if ana.lemma==an_word[1] and ana.gramm.split(\",\")[0]==pos_tag and set(ana.gramm.split(\",\")[1:])==an_word[3]:\n",
    "                    correct+=1\n",
    "    \n",
    "    \n",
    "    print(\"Total correct words: \", correct)\n",
    "    print(\"Total words: \", all)\n",
    "\n",
    "\n",
    "    all_total=0\n",
    "    all_lemma=0\n",
    "    all_pos=0\n",
    "    all_gramm=0\n",
    "    for pos_scores in scores:\n",
    "        all_total+=scores[pos_scores][\"total\"]\n",
    "        all_lemma+=scores[pos_scores][\"corr_lemma\"]\n",
    "        all_pos+=scores[pos_scores][\"corr_pos\"]\n",
    "        all_gramm+=scores[pos_scores][\"corr_gramm\"]\n",
    "    \n",
    "    scores[\"all\"][\"total\"]=all_total\n",
    "    scores[\"all\"][\"corr_lemma\"]=all_lemma\n",
    "    scores[\"all\"][\"corr_pos\"]=all_pos\n",
    "    scores[\"all\"][\"corr_gramm\"]=all_gramm\n",
    "\n",
    "    for pos_scores in scores:\n",
    "        scores[pos_scores][\"total_percent\"]=round(scores[pos_scores][\"total\"]*100/all_total, 2)\n",
    "        scores[pos_scores][\"corr_lemma_percent\"]=round(scores[pos_scores][\"corr_lemma\"]*100/scores[pos_scores][\"total\"], 2)\n",
    "        scores[pos_scores][\"corr_pos_percent\"]=round(scores[pos_scores][\"corr_pos\"]*100/scores[pos_scores][\"total\"], 2)\n",
    "        scores[pos_scores][\"corr_gramm_percent\"]=round(scores[pos_scores][\"corr_gramm\"]*100/scores[pos_scores][\"total\"], 2)\n",
    "\n",
    "    wam={\"lemma_wam\": 0, \"pos_wam\": 0, \"gramm_wam\": 0}\n",
    "    \n",
    "    for pos_scores in scores:\n",
    "        if pos_scores != \"all\":\n",
    "            wam[\"lemma_wam\"]+=scores[pos_scores][\"corr_lemma_percent\"]*scores[pos_scores][\"total_percent\"]\n",
    "            wam[\"pos_wam\"]+=scores[pos_scores][\"corr_pos_percent\"]*scores[pos_scores][\"total_percent\"]\n",
    "            wam[\"gramm_wam\"]+=scores[pos_scores][\"corr_gramm_percent\"]*scores[pos_scores][\"total_percent\"]\n",
    "\n",
    "    wam[\"lemma_wam\"]=round(wam[\"lemma_wam\"]/100, 2)\n",
    "    wam[\"pos_wam\"]=round(wam[\"pos_wam\"]/100, 2)\n",
    "    wam[\"gramm_wam\"]=round(wam[\"gramm_wam\"]/100, 2)\n",
    "\n",
    "    scores_df = pd.DataFrame(scores).drop([\"total_percent\"]).transpose()\n",
    "    scores_df[['total', 'corr_lemma', \"corr_pos\", \"corr_gramm\"]] = scores_df[['total', 'corr_lemma', \"corr_pos\", \"corr_gramm\"]].astype(int)\n",
    "\n",
    "    print(\"The weighted arithmetic mean: \", wam)\n",
    "\n",
    "    return scores_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total correct words:  938\n",
      "Total words:  1055\n",
      "The weighted arithmetic mean:  {'lemma_wam': 89.49, 'pos_wam': 89.68, 'gramm_wam': 88.92}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>total</th>\n",
       "      <th>corr_lemma</th>\n",
       "      <th>corr_lemma_percent</th>\n",
       "      <th>corr_pos</th>\n",
       "      <th>corr_pos_percent</th>\n",
       "      <th>corr_gramm</th>\n",
       "      <th>corr_gramm_percent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>NOUN</th>\n",
       "      <td>251</td>\n",
       "      <td>226</td>\n",
       "      <td>90.04</td>\n",
       "      <td>227</td>\n",
       "      <td>90.44</td>\n",
       "      <td>225</td>\n",
       "      <td>89.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VERB</th>\n",
       "      <td>296</td>\n",
       "      <td>227</td>\n",
       "      <td>76.69</td>\n",
       "      <td>228</td>\n",
       "      <td>77.03</td>\n",
       "      <td>222</td>\n",
       "      <td>75.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AUX</th>\n",
       "      <td>38</td>\n",
       "      <td>38</td>\n",
       "      <td>100.00</td>\n",
       "      <td>38</td>\n",
       "      <td>100.00</td>\n",
       "      <td>38</td>\n",
       "      <td>100.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ADJ</th>\n",
       "      <td>21</td>\n",
       "      <td>19</td>\n",
       "      <td>90.48</td>\n",
       "      <td>19</td>\n",
       "      <td>90.48</td>\n",
       "      <td>19</td>\n",
       "      <td>90.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ADV</th>\n",
       "      <td>53</td>\n",
       "      <td>47</td>\n",
       "      <td>88.68</td>\n",
       "      <td>47</td>\n",
       "      <td>88.68</td>\n",
       "      <td>47</td>\n",
       "      <td>88.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PRON</th>\n",
       "      <td>48</td>\n",
       "      <td>48</td>\n",
       "      <td>100.00</td>\n",
       "      <td>48</td>\n",
       "      <td>100.00</td>\n",
       "      <td>48</td>\n",
       "      <td>100.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NUM</th>\n",
       "      <td>23</td>\n",
       "      <td>23</td>\n",
       "      <td>100.00</td>\n",
       "      <td>23</td>\n",
       "      <td>100.00</td>\n",
       "      <td>23</td>\n",
       "      <td>100.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SCONJ</th>\n",
       "      <td>20</td>\n",
       "      <td>18</td>\n",
       "      <td>90.00</td>\n",
       "      <td>18</td>\n",
       "      <td>90.00</td>\n",
       "      <td>18</td>\n",
       "      <td>90.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CCONJ</th>\n",
       "      <td>83</td>\n",
       "      <td>83</td>\n",
       "      <td>100.00</td>\n",
       "      <td>83</td>\n",
       "      <td>100.00</td>\n",
       "      <td>83</td>\n",
       "      <td>100.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DET</th>\n",
       "      <td>29</td>\n",
       "      <td>29</td>\n",
       "      <td>100.00</td>\n",
       "      <td>29</td>\n",
       "      <td>100.00</td>\n",
       "      <td>29</td>\n",
       "      <td>100.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PREP</th>\n",
       "      <td>135</td>\n",
       "      <td>134</td>\n",
       "      <td>99.26</td>\n",
       "      <td>134</td>\n",
       "      <td>99.26</td>\n",
       "      <td>134</td>\n",
       "      <td>99.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PART</th>\n",
       "      <td>33</td>\n",
       "      <td>32</td>\n",
       "      <td>96.97</td>\n",
       "      <td>32</td>\n",
       "      <td>96.97</td>\n",
       "      <td>32</td>\n",
       "      <td>96.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>INTJ</th>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>88.89</td>\n",
       "      <td>8</td>\n",
       "      <td>88.89</td>\n",
       "      <td>8</td>\n",
       "      <td>88.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PROPN</th>\n",
       "      <td>16</td>\n",
       "      <td>12</td>\n",
       "      <td>75.00</td>\n",
       "      <td>12</td>\n",
       "      <td>75.00</td>\n",
       "      <td>12</td>\n",
       "      <td>75.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>all</th>\n",
       "      <td>1055</td>\n",
       "      <td>944</td>\n",
       "      <td>89.48</td>\n",
       "      <td>946</td>\n",
       "      <td>89.67</td>\n",
       "      <td>938</td>\n",
       "      <td>88.91</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       total  corr_lemma  corr_lemma_percent  corr_pos  corr_pos_percent  \\\n",
       "NOUN     251         226               90.04       227             90.44   \n",
       "VERB     296         227               76.69       228             77.03   \n",
       "AUX       38          38              100.00        38            100.00   \n",
       "ADJ       21          19               90.48        19             90.48   \n",
       "ADV       53          47               88.68        47             88.68   \n",
       "PRON      48          48              100.00        48            100.00   \n",
       "NUM       23          23              100.00        23            100.00   \n",
       "SCONJ     20          18               90.00        18             90.00   \n",
       "CCONJ     83          83              100.00        83            100.00   \n",
       "DET       29          29              100.00        29            100.00   \n",
       "PREP     135         134               99.26       134             99.26   \n",
       "PART      33          32               96.97        32             96.97   \n",
       "INTJ       9           8               88.89         8             88.89   \n",
       "PROPN     16          12               75.00        12             75.00   \n",
       "all     1055         944               89.48       946             89.67   \n",
       "\n",
       "       corr_gramm  corr_gramm_percent  \n",
       "NOUN          225               89.64  \n",
       "VERB          222               75.00  \n",
       "AUX            38              100.00  \n",
       "ADJ            19               90.48  \n",
       "ADV            47               88.68  \n",
       "PRON           48              100.00  \n",
       "NUM            23              100.00  \n",
       "SCONJ          18               90.00  \n",
       "CCONJ          83              100.00  \n",
       "DET            29              100.00  \n",
       "PREP          134               99.26  \n",
       "PART           32               96.97  \n",
       "INTJ            8               88.89  \n",
       "PROPN          12               75.00  \n",
       "all           938               88.91  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_annotation_scores(ann1, sents_ann)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total correct words:  557\n",
      "Total words:  670\n",
      "The weighted arithmetic mean:  {'lemma_wam': 84.03, 'pos_wam': 84.33, 'gramm_wam': 83.13}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>total</th>\n",
       "      <th>corr_lemma</th>\n",
       "      <th>corr_lemma_percent</th>\n",
       "      <th>corr_pos</th>\n",
       "      <th>corr_pos_percent</th>\n",
       "      <th>corr_gramm</th>\n",
       "      <th>corr_gramm_percent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>NOUN</th>\n",
       "      <td>208</td>\n",
       "      <td>185</td>\n",
       "      <td>88.94</td>\n",
       "      <td>186</td>\n",
       "      <td>89.42</td>\n",
       "      <td>184</td>\n",
       "      <td>88.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VERB</th>\n",
       "      <td>258</td>\n",
       "      <td>191</td>\n",
       "      <td>74.03</td>\n",
       "      <td>192</td>\n",
       "      <td>74.42</td>\n",
       "      <td>186</td>\n",
       "      <td>72.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AUX</th>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>100.00</td>\n",
       "      <td>18</td>\n",
       "      <td>100.00</td>\n",
       "      <td>18</td>\n",
       "      <td>100.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ADJ</th>\n",
       "      <td>20</td>\n",
       "      <td>18</td>\n",
       "      <td>90.00</td>\n",
       "      <td>18</td>\n",
       "      <td>90.00</td>\n",
       "      <td>18</td>\n",
       "      <td>90.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ADV</th>\n",
       "      <td>29</td>\n",
       "      <td>23</td>\n",
       "      <td>79.31</td>\n",
       "      <td>23</td>\n",
       "      <td>79.31</td>\n",
       "      <td>23</td>\n",
       "      <td>79.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PRON</th>\n",
       "      <td>21</td>\n",
       "      <td>21</td>\n",
       "      <td>100.00</td>\n",
       "      <td>21</td>\n",
       "      <td>100.00</td>\n",
       "      <td>21</td>\n",
       "      <td>100.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NUM</th>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>100.00</td>\n",
       "      <td>14</td>\n",
       "      <td>100.00</td>\n",
       "      <td>14</td>\n",
       "      <td>100.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SCONJ</th>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>80.00</td>\n",
       "      <td>8</td>\n",
       "      <td>80.00</td>\n",
       "      <td>8</td>\n",
       "      <td>80.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CCONJ</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>100.00</td>\n",
       "      <td>2</td>\n",
       "      <td>100.00</td>\n",
       "      <td>2</td>\n",
       "      <td>100.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DET</th>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>100.00</td>\n",
       "      <td>16</td>\n",
       "      <td>100.00</td>\n",
       "      <td>16</td>\n",
       "      <td>100.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PREP</th>\n",
       "      <td>39</td>\n",
       "      <td>38</td>\n",
       "      <td>97.44</td>\n",
       "      <td>38</td>\n",
       "      <td>97.44</td>\n",
       "      <td>38</td>\n",
       "      <td>97.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PART</th>\n",
       "      <td>12</td>\n",
       "      <td>11</td>\n",
       "      <td>91.67</td>\n",
       "      <td>11</td>\n",
       "      <td>91.67</td>\n",
       "      <td>11</td>\n",
       "      <td>91.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>INTJ</th>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>85.71</td>\n",
       "      <td>6</td>\n",
       "      <td>85.71</td>\n",
       "      <td>6</td>\n",
       "      <td>85.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PROPN</th>\n",
       "      <td>16</td>\n",
       "      <td>12</td>\n",
       "      <td>75.00</td>\n",
       "      <td>12</td>\n",
       "      <td>75.00</td>\n",
       "      <td>12</td>\n",
       "      <td>75.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>all</th>\n",
       "      <td>670</td>\n",
       "      <td>563</td>\n",
       "      <td>84.03</td>\n",
       "      <td>565</td>\n",
       "      <td>84.33</td>\n",
       "      <td>557</td>\n",
       "      <td>83.13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       total  corr_lemma  corr_lemma_percent  corr_pos  corr_pos_percent  \\\n",
       "NOUN     208         185               88.94       186             89.42   \n",
       "VERB     258         191               74.03       192             74.42   \n",
       "AUX       18          18              100.00        18            100.00   \n",
       "ADJ       20          18               90.00        18             90.00   \n",
       "ADV       29          23               79.31        23             79.31   \n",
       "PRON      21          21              100.00        21            100.00   \n",
       "NUM       14          14              100.00        14            100.00   \n",
       "SCONJ     10           8               80.00         8             80.00   \n",
       "CCONJ      2           2              100.00         2            100.00   \n",
       "DET       16          16              100.00        16            100.00   \n",
       "PREP      39          38               97.44        38             97.44   \n",
       "PART      12          11               91.67        11             91.67   \n",
       "INTJ       7           6               85.71         6             85.71   \n",
       "PROPN     16          12               75.00        12             75.00   \n",
       "all      670         563               84.03       565             84.33   \n",
       "\n",
       "       corr_gramm  corr_gramm_percent  \n",
       "NOUN          184               88.46  \n",
       "VERB          186               72.09  \n",
       "AUX            18              100.00  \n",
       "ADJ            18               90.00  \n",
       "ADV            23               79.31  \n",
       "PRON           21              100.00  \n",
       "NUM            14              100.00  \n",
       "SCONJ           8               80.00  \n",
       "CCONJ           2              100.00  \n",
       "DET            16              100.00  \n",
       "PREP           38               97.44  \n",
       "PART           11               91.67  \n",
       "INTJ            6               85.71  \n",
       "PROPN          12               75.00  \n",
       "all           557               83.13  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_annotation_scores(ann2, sents_ann)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total correct words:  938\n",
      "Total words:  952\n",
      "The weighted arithmetic mean:  {'lemma_wam': 99.18, 'pos_wam': 99.39, 'gramm_wam': 98.55}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>total</th>\n",
       "      <th>corr_lemma</th>\n",
       "      <th>corr_lemma_percent</th>\n",
       "      <th>corr_pos</th>\n",
       "      <th>corr_pos_percent</th>\n",
       "      <th>corr_gramm</th>\n",
       "      <th>corr_gramm_percent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>NOUN</th>\n",
       "      <td>229</td>\n",
       "      <td>226</td>\n",
       "      <td>98.69</td>\n",
       "      <td>227</td>\n",
       "      <td>99.13</td>\n",
       "      <td>225</td>\n",
       "      <td>98.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VERB</th>\n",
       "      <td>228</td>\n",
       "      <td>227</td>\n",
       "      <td>99.56</td>\n",
       "      <td>228</td>\n",
       "      <td>100.00</td>\n",
       "      <td>222</td>\n",
       "      <td>97.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AUX</th>\n",
       "      <td>38</td>\n",
       "      <td>38</td>\n",
       "      <td>100.00</td>\n",
       "      <td>38</td>\n",
       "      <td>100.00</td>\n",
       "      <td>38</td>\n",
       "      <td>100.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ADJ</th>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>100.00</td>\n",
       "      <td>19</td>\n",
       "      <td>100.00</td>\n",
       "      <td>19</td>\n",
       "      <td>100.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ADV</th>\n",
       "      <td>49</td>\n",
       "      <td>47</td>\n",
       "      <td>95.92</td>\n",
       "      <td>47</td>\n",
       "      <td>95.92</td>\n",
       "      <td>47</td>\n",
       "      <td>95.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PRON</th>\n",
       "      <td>48</td>\n",
       "      <td>48</td>\n",
       "      <td>100.00</td>\n",
       "      <td>48</td>\n",
       "      <td>100.00</td>\n",
       "      <td>48</td>\n",
       "      <td>100.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NUM</th>\n",
       "      <td>23</td>\n",
       "      <td>23</td>\n",
       "      <td>100.00</td>\n",
       "      <td>23</td>\n",
       "      <td>100.00</td>\n",
       "      <td>23</td>\n",
       "      <td>100.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SCONJ</th>\n",
       "      <td>19</td>\n",
       "      <td>18</td>\n",
       "      <td>94.74</td>\n",
       "      <td>18</td>\n",
       "      <td>94.74</td>\n",
       "      <td>18</td>\n",
       "      <td>94.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CCONJ</th>\n",
       "      <td>83</td>\n",
       "      <td>83</td>\n",
       "      <td>100.00</td>\n",
       "      <td>83</td>\n",
       "      <td>100.00</td>\n",
       "      <td>83</td>\n",
       "      <td>100.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DET</th>\n",
       "      <td>29</td>\n",
       "      <td>29</td>\n",
       "      <td>100.00</td>\n",
       "      <td>29</td>\n",
       "      <td>100.00</td>\n",
       "      <td>29</td>\n",
       "      <td>100.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PREP</th>\n",
       "      <td>134</td>\n",
       "      <td>134</td>\n",
       "      <td>100.00</td>\n",
       "      <td>134</td>\n",
       "      <td>100.00</td>\n",
       "      <td>134</td>\n",
       "      <td>100.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PART</th>\n",
       "      <td>32</td>\n",
       "      <td>32</td>\n",
       "      <td>100.00</td>\n",
       "      <td>32</td>\n",
       "      <td>100.00</td>\n",
       "      <td>32</td>\n",
       "      <td>100.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>INTJ</th>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>100.00</td>\n",
       "      <td>8</td>\n",
       "      <td>100.00</td>\n",
       "      <td>8</td>\n",
       "      <td>100.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PROPN</th>\n",
       "      <td>13</td>\n",
       "      <td>12</td>\n",
       "      <td>92.31</td>\n",
       "      <td>12</td>\n",
       "      <td>92.31</td>\n",
       "      <td>12</td>\n",
       "      <td>92.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>all</th>\n",
       "      <td>952</td>\n",
       "      <td>944</td>\n",
       "      <td>99.16</td>\n",
       "      <td>946</td>\n",
       "      <td>99.37</td>\n",
       "      <td>938</td>\n",
       "      <td>98.53</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       total  corr_lemma  corr_lemma_percent  corr_pos  corr_pos_percent  \\\n",
       "NOUN     229         226               98.69       227             99.13   \n",
       "VERB     228         227               99.56       228            100.00   \n",
       "AUX       38          38              100.00        38            100.00   \n",
       "ADJ       19          19              100.00        19            100.00   \n",
       "ADV       49          47               95.92        47             95.92   \n",
       "PRON      48          48              100.00        48            100.00   \n",
       "NUM       23          23              100.00        23            100.00   \n",
       "SCONJ     19          18               94.74        18             94.74   \n",
       "CCONJ     83          83              100.00        83            100.00   \n",
       "DET       29          29              100.00        29            100.00   \n",
       "PREP     134         134              100.00       134            100.00   \n",
       "PART      32          32              100.00        32            100.00   \n",
       "INTJ       8           8              100.00         8            100.00   \n",
       "PROPN     13          12               92.31        12             92.31   \n",
       "all      952         944               99.16       946             99.37   \n",
       "\n",
       "       corr_gramm  corr_gramm_percent  \n",
       "NOUN          225               98.25  \n",
       "VERB          222               97.37  \n",
       "AUX            38              100.00  \n",
       "ADJ            19              100.00  \n",
       "ADV            47               95.92  \n",
       "PRON           48              100.00  \n",
       "NUM            23              100.00  \n",
       "SCONJ          18               94.74  \n",
       "CCONJ          83              100.00  \n",
       "DET            29              100.00  \n",
       "PREP          134              100.00  \n",
       "PART           32              100.00  \n",
       "INTJ            8              100.00  \n",
       "PROPN          12               92.31  \n",
       "all           938               98.53  "
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_annotation_scores(ann3, sents_ann)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total correct words:  557\n",
      "Total words:  571\n",
      "The weighted arithmetic mean:  {'lemma_wam': 98.6, 'pos_wam': 98.95, 'gramm_wam': 97.55}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>total</th>\n",
       "      <th>corr_lemma</th>\n",
       "      <th>corr_lemma_percent</th>\n",
       "      <th>corr_pos</th>\n",
       "      <th>corr_pos_percent</th>\n",
       "      <th>corr_gramm</th>\n",
       "      <th>corr_gramm_percent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>NOUN</th>\n",
       "      <td>188</td>\n",
       "      <td>185</td>\n",
       "      <td>98.40</td>\n",
       "      <td>186</td>\n",
       "      <td>98.94</td>\n",
       "      <td>184</td>\n",
       "      <td>97.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VERB</th>\n",
       "      <td>192</td>\n",
       "      <td>191</td>\n",
       "      <td>99.48</td>\n",
       "      <td>192</td>\n",
       "      <td>100.00</td>\n",
       "      <td>186</td>\n",
       "      <td>96.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AUX</th>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>100.00</td>\n",
       "      <td>18</td>\n",
       "      <td>100.00</td>\n",
       "      <td>18</td>\n",
       "      <td>100.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ADJ</th>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>100.00</td>\n",
       "      <td>18</td>\n",
       "      <td>100.00</td>\n",
       "      <td>18</td>\n",
       "      <td>100.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ADV</th>\n",
       "      <td>25</td>\n",
       "      <td>23</td>\n",
       "      <td>92.00</td>\n",
       "      <td>23</td>\n",
       "      <td>92.00</td>\n",
       "      <td>23</td>\n",
       "      <td>92.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PRON</th>\n",
       "      <td>21</td>\n",
       "      <td>21</td>\n",
       "      <td>100.00</td>\n",
       "      <td>21</td>\n",
       "      <td>100.00</td>\n",
       "      <td>21</td>\n",
       "      <td>100.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NUM</th>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>100.00</td>\n",
       "      <td>14</td>\n",
       "      <td>100.00</td>\n",
       "      <td>14</td>\n",
       "      <td>100.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SCONJ</th>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>88.89</td>\n",
       "      <td>8</td>\n",
       "      <td>88.89</td>\n",
       "      <td>8</td>\n",
       "      <td>88.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CCONJ</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>100.00</td>\n",
       "      <td>2</td>\n",
       "      <td>100.00</td>\n",
       "      <td>2</td>\n",
       "      <td>100.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DET</th>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>100.00</td>\n",
       "      <td>16</td>\n",
       "      <td>100.00</td>\n",
       "      <td>16</td>\n",
       "      <td>100.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PREP</th>\n",
       "      <td>38</td>\n",
       "      <td>38</td>\n",
       "      <td>100.00</td>\n",
       "      <td>38</td>\n",
       "      <td>100.00</td>\n",
       "      <td>38</td>\n",
       "      <td>100.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PART</th>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>100.00</td>\n",
       "      <td>11</td>\n",
       "      <td>100.00</td>\n",
       "      <td>11</td>\n",
       "      <td>100.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>INTJ</th>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>100.00</td>\n",
       "      <td>6</td>\n",
       "      <td>100.00</td>\n",
       "      <td>6</td>\n",
       "      <td>100.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PROPN</th>\n",
       "      <td>13</td>\n",
       "      <td>12</td>\n",
       "      <td>92.31</td>\n",
       "      <td>12</td>\n",
       "      <td>92.31</td>\n",
       "      <td>12</td>\n",
       "      <td>92.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>all</th>\n",
       "      <td>571</td>\n",
       "      <td>563</td>\n",
       "      <td>98.60</td>\n",
       "      <td>565</td>\n",
       "      <td>98.95</td>\n",
       "      <td>557</td>\n",
       "      <td>97.55</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       total  corr_lemma  corr_lemma_percent  corr_pos  corr_pos_percent  \\\n",
       "NOUN     188         185               98.40       186             98.94   \n",
       "VERB     192         191               99.48       192            100.00   \n",
       "AUX       18          18              100.00        18            100.00   \n",
       "ADJ       18          18              100.00        18            100.00   \n",
       "ADV       25          23               92.00        23             92.00   \n",
       "PRON      21          21              100.00        21            100.00   \n",
       "NUM       14          14              100.00        14            100.00   \n",
       "SCONJ      9           8               88.89         8             88.89   \n",
       "CCONJ      2           2              100.00         2            100.00   \n",
       "DET       16          16              100.00        16            100.00   \n",
       "PREP      38          38              100.00        38            100.00   \n",
       "PART      11          11              100.00        11            100.00   \n",
       "INTJ       6           6              100.00         6            100.00   \n",
       "PROPN     13          12               92.31        12             92.31   \n",
       "all      571         563               98.60       565             98.95   \n",
       "\n",
       "       corr_gramm  corr_gramm_percent  \n",
       "NOUN          184               97.87  \n",
       "VERB          186               96.88  \n",
       "AUX            18              100.00  \n",
       "ADJ            18              100.00  \n",
       "ADV            23               92.00  \n",
       "PRON           21              100.00  \n",
       "NUM            14              100.00  \n",
       "SCONJ           8               88.89  \n",
       "CCONJ           2              100.00  \n",
       "DET            16              100.00  \n",
       "PREP           38              100.00  \n",
       "PART           11              100.00  \n",
       "INTJ            6              100.00  \n",
       "PROPN          12               92.31  \n",
       "all           557               97.55  "
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_annotation_scores(ann4, sents_ann)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
